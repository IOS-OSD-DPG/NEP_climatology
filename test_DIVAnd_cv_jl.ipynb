{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a60bce2",
   "metadata": {},
   "source": [
    "# Testing DIVAnd_cv in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca65f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DIVAnd\n",
    "using CSV\n",
    "using DataFrames\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using NCDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2459971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\HourstonH\\\\Documents\\\\NEP_climatology\\\\diva_explore\\\\correlation_length\\\\cross_validation\\\\from_julia\\\\\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_name = \"Oxy\"\n",
    "year = 2010\n",
    "szn = \"OND\"\n",
    "subsamp_interval = 1\n",
    "\n",
    "obs_dir = string(\"C:\\\\Users\\\\HourstonH\\\\Documents\\\\NEP_climatology\\\\data\\\\\", \n",
    "    \"value_vs_depth\\\\14_sep_by_sl_and_year\\\\\")\n",
    "\n",
    "# GEBCO 6 minute mask\n",
    "mask_dir = string(\"C:\\\\Users\\\\HourstonH\\\\Documents\\\\NEP_climatology\\\\data\\\\\",\n",
    "    \"value_vs_depth\\\\16_diva_analysis\\\\masks\\\\\")\n",
    "\n",
    "output_dir = string(\"C:\\\\Users\\\\HourstonH\\\\Documents\\\\NEP_climatology\\\\\", \n",
    "    \"diva_explore\\\\correlation_length\\\\cross_validation\\\\from_julia\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0fd1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign some parameters\n",
    "\n",
    "# domain_size_x_deg = -115 - (-160)  # Degrees\n",
    "# domain_size_y_deg = 60 - 30\n",
    "# domain_size_x_m = DIVAnd.deg2m(domain_size_x_deg)\n",
    "# domain_size_y_m = DIVAnd.deg2m(domain_size_y_deg)\n",
    "\n",
    "# println(domain_size_x_m/10)\n",
    "# println(domain_size_y_m/10)\n",
    "\n",
    "# lenx = 500e3 # domain_size_x_m/10  # 500e3\n",
    "# leny = 500e3 # domain_size_y_m/10  # 500e3\n",
    "\n",
    "signal_to_noise_ratio = 50.  # Default from Lu ODV session\n",
    "epsilon2 = 1/signal_to_noise_ratio  # 1.\n",
    "\n",
    "# Choose number of testing points around the current value of L (corlen)\n",
    "nl = 1\n",
    "\n",
    "# Choose number of testing points around the current value of epsilon2\n",
    "ne = 1\n",
    "\n",
    "# Choose cross-validation method\n",
    "# 1: full CV; 2: sampled CV; 3: GCV; 0: automatic choice between the three\n",
    "method = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258dd8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HourstonH\\Documents\\NEP_climatology\\data\\value_vs_depth\\14_sep_by_sl_and_year\\Oxy_0m_2010_OND.csv\n",
      "lenx: 1.6538494; leny: 19.0285664\n",
      "Made Lon2d, Lat2d\n",
      "Computed pm, pn\n",
      "new lenx: 0.8020662566955302; new leny: 9.228271342439246\n",
      "0.0308746060066084\n",
      "C:\\Users\\HourstonH\\Documents\\NEP_climatology\\data\\value_vs_depth\\14_sep_by_sl_and_year\\Oxy_5m_2010_OND.csv\n",
      "lenx: 1.6538494; leny: 19.0285664\n",
      "Made Lon2d, Lat2d\n",
      "Computed pm, pn\n",
      "new lenx: 0.6004764230346993; new leny: 6.90885487357571\n",
      "0.0004477442277136678\n",
      "C:\\Users\\HourstonH\\Documents\\NEP_climatology\\data\\value_vs_depth\\14_sep_by_sl_and_year\\Oxy_10m_2010_OND.csv\n",
      "lenx: 1.6538494; leny: 19.030883\n",
      "Made Lon2d, Lat2d"
     ]
    }
   ],
   "source": [
    "# Initialize arrays to hold new lenx and epsilon2\n",
    "lenx_01_domain = []\n",
    "leny_01_domain = []\n",
    "lenx_cv = []\n",
    "leny_cv = []\n",
    "epsilon2_arr = []\n",
    "\n",
    "# Iterate through standard depths\n",
    "for standard_depth=[0:5:100;]\n",
    "    \n",
    "    # Read in standard level data file\n",
    "    obs_filename = string(obs_dir, var_name, \"_\", standard_depth, \"m_\", year, \n",
    "        \"_\", szn, \".csv\")\n",
    "    \n",
    "    println(obs_filename)\n",
    "    \n",
    "    # Pipe operator to dataframe\n",
    "    obs_df = CSV.File(obs_filename) |> DataFrame\n",
    "    \n",
    "    if size(obs_df)[1] == 0\n",
    "        println(\"DataFrame empty -- skipping\")\n",
    "        continue\n",
    "    end\n",
    "    \n",
    "    xobs = obs_df[!, :Longitude]\n",
    "    yobs = obs_df[!, :Latitude]\n",
    "    vobs = obs_df[!, :SL_value]\n",
    "    \n",
    "    # Calculate domain size based on the observations\n",
    "    # Set first guesses for correlation length as 1/10 domain size\n",
    "    domain_size_x_deg = maximum(xobs) - minimum(xobs)\n",
    "    domain_size_y_deg = maximum(yobs) - minimum(xobs)\n",
    "    lenx_guess = domain_size_x_deg/10\n",
    "    leny_guess = domain_size_y_deg/10\n",
    "    \n",
    "    # Append first guesses to arrays\n",
    "    push!(lenx_01_domain, lenx_guess)\n",
    "    push!(leny_01_domain, leny_guess)\n",
    "    \n",
    "    println(\"lenx: \", lenx_guess, \"; leny: \", leny_guess)\n",
    "    \n",
    "    # Read in mask\n",
    "    mask_filename = string(mask_dir, var_name, \"_\", standard_depth, \"m_\", \n",
    "        year, \"_\", szn, \"_mask_6min.nc\")\n",
    "    \n",
    "    mask_ds = Dataset(mask_filename)\n",
    "    \n",
    "    # Equivalent to numpy.meshgrid()\n",
    "    Lon2d, Lat2d = ndgrid(mask_ds[\"lon\"][1:subsamp_interval:end], \n",
    "        mask_ds[\"lat\"][1:subsamp_interval:end])\n",
    "    \n",
    "    println(\"Made Lon2d, Lat2d\")\n",
    "    \n",
    "    mask = mask_ds[\"mask\"][1:subsamp_interval:end, 1:subsamp_interval:end]\n",
    "    mask = Bool.(mask)\n",
    "#     println(typeof(mask))\n",
    "        \n",
    "    # Assign parameters\n",
    "    pm, pn = DIVAnd_metric(Lon2d, Lat2d)\n",
    "    \n",
    "    println(\"Computed pm, pn\")\n",
    "        \n",
    "    # Compute anomaly field\n",
    "    vmean = mean(vobs)\n",
    "    vanom = vobs .- vmean\n",
    "    \n",
    "#     println(size(vanom))\n",
    "    \n",
    "    # Run the cross-validation\n",
    "    # Need to take transpose?? transpose(A) = A'\n",
    "    bestfactorl, bestfactore, cvval, cvvalues, x2Ddata, y2Ddata, cvinter, xi2D, yi2D = DIVAnd_cv(\n",
    "        mask, (pm, pn), (Lon2d, Lat2d), (xobs, yobs), vanom, (lenx_guess, leny_guess), \n",
    "        epsilon2, nl, ne, method)\n",
    "    \n",
    "    new_lenx = bestfactorl .* lenx_guess\n",
    "    new_leny = bestfactorl .* leny_guess\n",
    "    new_epsilon2 = bestfactore .* epsilon2\n",
    "    println(\"new lenx: \", new_lenx, \"; new leny: \", new_leny)\n",
    "    println(new_epsilon2)\n",
    "    \n",
    "    # Append new values to the arrays\n",
    "    push!(lenx_cv, new_lenx)\n",
    "    push!(leny_cv, new_leny)\n",
    "    push!(epsilon2_arr, new_epsilon2)\n",
    "    \n",
    "    # Close mask dataset\n",
    "    close(mask_ds)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28988008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>21 rows × 6 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>depth</th><th>lenx_01_domain</th><th>leny_01_domain</th><th>lenx_cv</th><th>leny_cv</th><th>epsilon2</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th></tr></thead><tbody><tr><th>1</th><td>0</td><td>1.65385</td><td>19.0286</td><td>20.8207</td><td>239.555</td><td>0.0531271</td></tr><tr><th>2</th><td>5</td><td>1.65385</td><td>19.0286</td><td>20.8207</td><td>239.555</td><td>0.0344147</td></tr><tr><th>3</th><td>10</td><td>1.65385</td><td>19.0309</td><td>20.8207</td><td>239.585</td><td>0.0476621</td></tr><tr><th>4</th><td>15</td><td>1.65118</td><td>19.0309</td><td>20.7872</td><td>239.585</td><td>0.0592187</td></tr><tr><th>5</th><td>20</td><td>1.65118</td><td>19.0309</td><td>20.7872</td><td>239.585</td><td>0.0592187</td></tr><tr><th>6</th><td>25</td><td>1.65118</td><td>19.0309</td><td>20.7872</td><td>239.585</td><td>0.0592187</td></tr><tr><th>7</th><td>30</td><td>1.65118</td><td>19.0309</td><td>20.7872</td><td>239.585</td><td>0.0592187</td></tr><tr><th>8</th><td>35</td><td>1.65118</td><td>19.0309</td><td>20.7872</td><td>239.585</td><td>0.0592187</td></tr><tr><th>9</th><td>40</td><td>1.65118</td><td>19.0309</td><td>0.800773</td><td>9.22939</td><td>0.000447744</td></tr><tr><th>10</th><td>45</td><td>1.65118</td><td>19.0309</td><td>0.744871</td><td>8.58509</td><td>0.000447744</td></tr><tr><th>11</th><td>50</td><td>1.65118</td><td>19.0309</td><td>0.744871</td><td>8.58509</td><td>0.000447744</td></tr><tr><th>12</th><td>55</td><td>1.65118</td><td>19.0309</td><td>0.744871</td><td>8.58509</td><td>0.000447744</td></tr><tr><th>13</th><td>60</td><td>1.65118</td><td>19.0309</td><td>0.744871</td><td>8.58509</td><td>0.000447744</td></tr><tr><th>14</th><td>65</td><td>1.65118</td><td>19.0309</td><td>0.744871</td><td>8.58509</td><td>0.000447744</td></tr><tr><th>15</th><td>70</td><td>1.64202</td><td>19.0309</td><td>0.740735</td><td>8.58509</td><td>0.000447744</td></tr><tr><th>16</th><td>75</td><td>1.64202</td><td>19.0309</td><td>0.740735</td><td>8.58509</td><td>0.000447744</td></tr><tr><th>17</th><td>80</td><td>1.64202</td><td>19.0309</td><td>20.6718</td><td>239.585</td><td>0.0531271</td></tr><tr><th>18</th><td>85</td><td>1.64202</td><td>19.0309</td><td>0.796327</td><td>9.22939</td><td>0.000447744</td></tr><tr><th>19</th><td>90</td><td>1.64202</td><td>19.0309</td><td>20.6718</td><td>239.585</td><td>0.0592187</td></tr><tr><th>20</th><td>95</td><td>1.64202</td><td>19.0309</td><td>20.6718</td><td>239.585</td><td>0.0476621</td></tr><tr><th>21</th><td>100</td><td>1.64202</td><td>19.0309</td><td>20.6718</td><td>239.585</td><td>0.0592187</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& depth & lenx\\_01\\_domain & leny\\_01\\_domain & lenx\\_cv & leny\\_cv & epsilon2\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Any & Any & Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & 0 & 1.65385 & 19.0286 & 20.8207 & 239.555 & 0.0531271 \\\\\n",
       "\t2 & 5 & 1.65385 & 19.0286 & 20.8207 & 239.555 & 0.0344147 \\\\\n",
       "\t3 & 10 & 1.65385 & 19.0309 & 20.8207 & 239.585 & 0.0476621 \\\\\n",
       "\t4 & 15 & 1.65118 & 19.0309 & 20.7872 & 239.585 & 0.0592187 \\\\\n",
       "\t5 & 20 & 1.65118 & 19.0309 & 20.7872 & 239.585 & 0.0592187 \\\\\n",
       "\t6 & 25 & 1.65118 & 19.0309 & 20.7872 & 239.585 & 0.0592187 \\\\\n",
       "\t7 & 30 & 1.65118 & 19.0309 & 20.7872 & 239.585 & 0.0592187 \\\\\n",
       "\t8 & 35 & 1.65118 & 19.0309 & 20.7872 & 239.585 & 0.0592187 \\\\\n",
       "\t9 & 40 & 1.65118 & 19.0309 & 0.800773 & 9.22939 & 0.000447744 \\\\\n",
       "\t10 & 45 & 1.65118 & 19.0309 & 0.744871 & 8.58509 & 0.000447744 \\\\\n",
       "\t11 & 50 & 1.65118 & 19.0309 & 0.744871 & 8.58509 & 0.000447744 \\\\\n",
       "\t12 & 55 & 1.65118 & 19.0309 & 0.744871 & 8.58509 & 0.000447744 \\\\\n",
       "\t13 & 60 & 1.65118 & 19.0309 & 0.744871 & 8.58509 & 0.000447744 \\\\\n",
       "\t14 & 65 & 1.65118 & 19.0309 & 0.744871 & 8.58509 & 0.000447744 \\\\\n",
       "\t15 & 70 & 1.64202 & 19.0309 & 0.740735 & 8.58509 & 0.000447744 \\\\\n",
       "\t16 & 75 & 1.64202 & 19.0309 & 0.740735 & 8.58509 & 0.000447744 \\\\\n",
       "\t17 & 80 & 1.64202 & 19.0309 & 20.6718 & 239.585 & 0.0531271 \\\\\n",
       "\t18 & 85 & 1.64202 & 19.0309 & 0.796327 & 9.22939 & 0.000447744 \\\\\n",
       "\t19 & 90 & 1.64202 & 19.0309 & 20.6718 & 239.585 & 0.0592187 \\\\\n",
       "\t20 & 95 & 1.64202 & 19.0309 & 20.6718 & 239.585 & 0.0476621 \\\\\n",
       "\t21 & 100 & 1.64202 & 19.0309 & 20.6718 & 239.585 & 0.0592187 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m21×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m depth \u001b[0m\u001b[1m lenx_01_domain \u001b[0m\u001b[1m leny_01_domain \u001b[0m\u001b[1m lenx_cv  \u001b[0m\u001b[1m leny_cv \u001b[0m\u001b[1m epsilon2    \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Any            \u001b[0m\u001b[90m Any            \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Any         \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────────────────────────\n",
       "   1 │     0  1.65385         19.0286         20.8207   239.555  0.0531271\n",
       "   2 │     5  1.65385         19.0286         20.8207   239.555  0.0344147\n",
       "   3 │    10  1.65385         19.0309         20.8207   239.585  0.0476621\n",
       "   4 │    15  1.65118         19.0309         20.7872   239.585  0.0592187\n",
       "   5 │    20  1.65118         19.0309         20.7872   239.585  0.0592187\n",
       "   6 │    25  1.65118         19.0309         20.7872   239.585  0.0592187\n",
       "   7 │    30  1.65118         19.0309         20.7872   239.585  0.0592187\n",
       "   8 │    35  1.65118         19.0309         20.7872   239.585  0.0592187\n",
       "   9 │    40  1.65118         19.0309         0.800773  9.22939  0.000447744\n",
       "  10 │    45  1.65118         19.0309         0.744871  8.58509  0.000447744\n",
       "  11 │    50  1.65118         19.0309         0.744871  8.58509  0.000447744\n",
       "  12 │    55  1.65118         19.0309         0.744871  8.58509  0.000447744\n",
       "  13 │    60  1.65118         19.0309         0.744871  8.58509  0.000447744\n",
       "  14 │    65  1.65118         19.0309         0.744871  8.58509  0.000447744\n",
       "  15 │    70  1.64202         19.0309         0.740735  8.58509  0.000447744\n",
       "  16 │    75  1.64202         19.0309         0.740735  8.58509  0.000447744\n",
       "  17 │    80  1.64202         19.0309         20.6718   239.585  0.0531271\n",
       "  18 │    85  1.64202         19.0309         0.796327  9.22939  0.000447744\n",
       "  19 │    90  1.64202         19.0309         20.6718   239.585  0.0592187\n",
       "  20 │    95  1.64202         19.0309         20.6718   239.585  0.0476621\n",
       "  21 │   100  1.64202         19.0309         20.6718   239.585  0.0592187"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dataframe\n",
    "df_out = DataFrame(depth=[0:5:100;], lenx_01_domain=lenx_01_domain, \n",
    "    leny_01_domain=leny_01_domain, lenx_cv = lenx_cv, leny_cv = leny_cv, \n",
    "    epsilon2 = epsilon2_arr)\n",
    "\n",
    "# print(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6590a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6485082476190478 19.030662371428576\n",
      "12.18514070949573 140.64340617680034 0.031169203073309153\n",
      "20.67175668972613; 239.55545790972658; 0.04766206480316496\n"
     ]
    }
   ],
   "source": [
    "# Print summary stats\n",
    "mean_lenx = mean(df_out[!, \"lenx_cv\"])\n",
    "mean_leny = mean(df_out[!, \"leny_cv\"])\n",
    "mean_epsilon2 = mean(df_out[!, \"epsilon2\"])\n",
    "\n",
    "println(mean(df_out[!, \"lenx_01_domain\"]), \" \", mean(df_out[!, \"leny_01_domain\"]))\n",
    "println(mean_lenx, \" \", mean_leny, \" \", mean_epsilon2)\n",
    "println(median(df_out[!, \"lenx_cv\"]), \"; \", median(df_out[!, \"leny_cv\"]), \"; \", \n",
    "    median(df_out[!, \"epsilon2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a337a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\HourstonH\\\\Documents\\\\NEP_climatology\\\\diva_explore\\\\correlation_length\\\\cross_validation\\\\from_julia\\\\Oxy_2010_OND_cv_results_top100m.csv\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the dataframe as a csv file\n",
    "df_filename = string(output_dir, var_name, \"_\", year, \"_\", szn, \n",
    "    \"_cv_results_top100m.csv\")\n",
    "\n",
    "CSV.write(df_filename, df_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51fe1e",
   "metadata": {},
   "source": [
    "# Random code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi, yi = ndgrid(range(0, stop=1, length=20), range(0, stop=1, length=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5075eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi[1:5:length(xi)]  # Take transpose??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [1:2:10;]\n",
    "maximum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[1:3:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(([0:1:10], [0:2:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499dda10",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "arr = [1 2 3; 4 5 6; 7 8 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in mask\n",
    "standard_depth = 0\n",
    "\n",
    "mask_filename = string(mask_dir, var_name, \"_\", standard_depth, \"m_\", \n",
    "    year, \"_\", szn, \"_mask_6min.nc\")\n",
    "    \n",
    "mask_ds = Dataset(mask_filename)\n",
    "\n",
    "# convert to true/false\n",
    "mask_tf = mask_ds[\"mask\"][:]\n",
    "\n",
    "# mask_tf[mask_tf .== 1] .= true\n",
    "# mask_tf[mask_tf .== 0] .= false\n",
    "\n",
    "typeof(Bool.(mask_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcad80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_filename = string(obs_dir, var_name, \"_\", 0, \"m_\", year, \n",
    "        \"_\", szn, \".csv\")\n",
    "\n",
    "obs_df = CSV.File(obs_filename) |> DataFrame\n",
    "\n",
    "size(obs_df)[1] == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
